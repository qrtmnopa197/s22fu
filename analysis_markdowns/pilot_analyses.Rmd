---
title: "Final analysis"
author: "Daniel Parr"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "/Users/dp/projects/spring_2022_study/data_review_analysis_records") })
output: html_document
---
# Overview
This markdown contains the final set of analyses done on s22 data for the manuscript.

# Setting up
Loading in functions and data; setting paths and options.
```{r 1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=6)

##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")

library(GGally)
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(bayesplot)
library(sigmoid)

source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))

trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-10_11_08_01.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-10_11_08_01.csv"))
```

# Pre-processing
Eliminate subject who fail to meet quality standards

```{r 2}
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
                            percent_left > .8 |
                            percent_left < .2 |
                            consecutive_late_choices > 5 |
                            late_percent > .2 |
                            answers_incorrect > 2 |
                            trials_completed < 104 |
                            valrate_skipped_percent > .14 |
                            valence_sd < .1 |
                            decrate_sd < .05 |
                            feedrate_sd < .05)

#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
  subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
                                  subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
                                  subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs

subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion

trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
#trials <- trials %>% filter(!(id %in% c(86077,86134,86356,87163,86458,85588,86869,86956,86746,79198,86359,86503,86881))) %>% filter(choice != "late")
```


LEFT OFF HERE

Do a few data transformations.
```{r 3}
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.

#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects

#get mean-centeeed trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)                                                          
trials$block_cent <- trials$block - mean(trials$block) 

#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")

#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))

#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
```

# Data review

```{r}
percentage_plots(trials,"stay")
```

```{r}
choice_fit <- lmer(choice_numeric ~ fB_win_prob + fA_win_prob + (1|id),trials)
summary(choice_fit)
```

```{r}
stay_fit <- lmer(stay ~ chosen_out + unchosen_out + (1|id),trials)
summary(stay_fit)
```

# Choice models

Fitting Q-learning models to choice.

## Null model

Starting by fitting a a null model (random choice) for reference. 
```{r 4}
null_qlearn <- fit_stan_model(stan_file = paste0(stan_model_dir_s22,"null_qlearn.stan"),
                         model_out_dir = model_out_dir,
                         raw_data = trials,
                         study = "s22fu",
                         skip=c("waic","check_csvs"),
                         n_t=104,
                         chains = 2,
                         fixed_param = TRUE
                         )
```


## Raw Q-learning

Fitting a basic Q-learning model with no nuisance parameters.
```{r 5}
basic_qlearn <- fit_stan_model(stan_file = paste0(stan_model_dir_s22,"basic_qlearn.stan"),
                         model_out_dir = model_out_dir,
                         raw_data = trials,
                         study = "s22fu",
                         skip=c("waic","check_csvs"),
                         n_t=104,
                         chains = 2)
```

```{r}
fsml_compare(basic_qlearn,null_qlearn)
```

```{r}
filt_sum(basic_qlearn$sum,"mu")
```

## Q-learning with autocorrelation

Now adding an autocorrelation component to the Q-learning model.
```{r}
autocor_qlearn <- fit_stan_model(stan_file = paste0(stan_model_dir_s22,"autocor_qlearn.stan"),
                         model_out_dir = model_out_dir,
                         raw_data = trials,
                         study = "s22fu",
                         skip=c("waic","check_csvs"),
                         n_t=104,
                         chains = 2)
```

```{r}
fsml_compare(basic_qlearn,autocor_qlearn)
```

```{r}
filt_sum(autocor_qlearn$sum,"mu")
```

## Winning choice model review

Verifying that the effect of reward on choice is consistently positive by looking at the subject-level mean beta values.
```{r}
ncp_mean_hist(autocor_qlearn$sum,"beta")
```

# Affect models

Combined model

```{r}
affect_full <- fit_stan_model(stan_file = paste0(stan_model_dir_s22fu,"affect_full.stan"),
                         model_out_dir = model_out_dir,
                         raw_data = trials,
                         study = "s22fu",
                         skip=c("waic","check_csvs"),
                         n_t=104)
```

```{r}
filt_sum(affect_full$sum,"mu")
```

```{r}
all_features <- fit_stan_model(stan_file = paste0(stan_model_dir_s22fu,"all_features.stan"),
                         model_out_dir = model_out_dir,
                         raw_data = trials,
                         study = "s22fu",
                         skip=c("waic","check_csvs"),
                         n_t=104)
```
