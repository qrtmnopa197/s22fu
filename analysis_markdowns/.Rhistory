area_method = "scaled height",
prob = 0.9,
prob_outer = 0.99,
point_est = "median"
) +
coord_cartesian(xlim = c(0,NA))
mcmc_areas(
asens_draws,
area_method = "scaled height",
prob = 0.9,
prob_outer = 0.99,
point_est = "median"
)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(GGally)
library(bayesplot)
library(sigmoid)
library(abind)
source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-12_09_56_03.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-12_09_56_03.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 104 |
valrate_skipped_percent > .14 |
valence_sd < .1 |
decrate_sd < .05 |
feedrate_sd < .05)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#get mean-centered trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
mod <- cmdstan_model("~/Desktop/test.stan", pedantic=T) #generate model object
fit <- mod$sample(fixed_param=TRUE) #run stan on model
fit$summary()
sd(c(5,12,13,-4,-11,22))
temp <- read_fsml("ratings_arl",model_out_dir=model_out_dir)
temp$diagnostics
trials_frate <- trials %>% filter(block_feedrate == 1) #get only trials from feedback rating blocks
sigmoid(-.6)
test <- read_fsml("model_pred_arl_nonuis",model_out_dir=model_out_dir)
test$diagnostics
ratings_arl$diagnostics
filt_sum(ratings_arl$sum,"scd")
ra_scd_draws <- get_draws("ratings_arl",model_out_dir=model_out_dir,vars=c("scd_beta_mu","scd_aff_sens_mu","scd_phi_mu"))
quantile(ra_scd_draws[,,"scd_beta_mu"],c(.025,.50,.975))
sigmoid(1.38)
quantile(ra_scd_draws[,,"scd_aff_sens_mu"],c(.025,.50,.975))
sigmoid(.3)
3.48/.61
1.39/.3
ratings_arl <- ""
ra_scd_draws <- ""
ratings_arl$diagnostics
model_pred_arl_nonuis$diagnostics
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lme4)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
test <- read_fsml("two_q",model_out_dir=model_out_dir)
test$diagnostics
filter(test$diagnostics$Rhat,grepl("lik",variable))
filter(test$diagnostics$Rhat,grepl("lik",variable,invert=T))
filter(test$diagnostics$Rhat,grepl("lik",variable)==F)
filter(test$diagnostics$ESS,grepl("lik",variable)==F)
view(filter(test$diagnostics$ESS,grepl("lik",variable)==F))
t <- read_fsml("breakdown",model_out_dir=model_out_dir)
t$runtime
557.5/60
t <- ""
t <- read_fsml("breakdown",model_out_dir=model_out_dir)
t$diagnostics
test <- read_fsml("breakdown",model_out_dir=model_out_dir)
test$diagnostics
view(test$diagnostics$ESS)
test$runtime
557.5/60
300/50
46512/144
breakdown$diagnostics
two_q$diagnostics
two_q_scds <- get_draws("two_q",model_out_dir=model_out_dir,vars = c("scd_aff_sens_mu","scd_rew_sens_mu","scd_csens_mu",))
two_q_scds <- get_draws("two_q",model_out_dir=model_out_dir,vars = c("scd_aff_sens_mu","scd_rew_sens_mu","scd_csens_mu"))
two_q_scds <- get_draws("two_q",model_out_dir=model_out_dir,vars = c("scd_aff_fr_sens_mu","scd_rew_fr_sens_mu","scd_csens_mu"))
quantile(two_q_scds[,,"scd_aff_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_aff_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_rew_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_aff_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_rew_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_aff_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_rew_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_aff_fr_sens_mu"],c(.025,.5,.975))
quantile(two_q_scds[,,"scd_rew_fr_sens_mu"],c(.025,.5,.975))
sigmoid(.24)
library(sigmoid)
sigmoid(.24)
sigmoid(.56)
two_q_scds <- ""
two_q <- ""
test <- ""
t <- ""
tb_scds <- get_draws("test_breakdown",model_out_dir=model_out_dir,vars = c("scd_aff_fr_sens_mu","scd_rew_fr_sens_mu","scd_csens_mu"))
tb_scds <- get_draws("temp_breakdown",model_out_dir=model_out_dir,vars = c("scd_aff_fr_sens_mu","scd_rew_fr_sens_mu","scd_csens_mu"))
quantile(tb_scds[,,"scd_aff_fr_sens_mu"],c(.025,.5,.975))
quantile(tb_scds[,,"scd_rew_fr_sens_mu"],c(.025,.5,.975))
sigmoid(.65)
mean(tb_scds[,,"scd_aff_fr_sens_mu"] - tb_scds[,,"scd_rew_fr_sens_mu"] > 0_
mean(tb_scds[,,"scd_aff_fr_sens_mu"] - tb_scds[,,"scd_rew_fr_sens_mu"] > 0)
quantile(tb_scds[,,"scd_ma_fr_sens_mu"],c(.025,.5,.975))
spef_scds <- get_draws("temp_breakdown",model_out_dir=model_out_dir,vars = c("scd_ma_fr_sens_mu","scd_resid_fr_sens_mu","scd_nuis_fr_sens_mu"))
mean(spef_scds[,,"scd_ma_fr_sens_mu"] - tb_scds[,,"scd_rew_fr_sens_mu"] > 0)*100
mean(spef_scds[,,"scd_resid_fr_sens_mu"] - tb_scds[,,"scd_rew_fr_sens_mu"] > 0)*100
quantile(spef_scds[,,"scd_ma_fr_sens_mu"])
quantile(spef_scds[,,"scd_resid_fr_sens_mu"])
quantile(spef_scds[,,"scd_rew_fr_sens_mu"])
sigmiod(.63)
sigmoid(.63)
quantile(tb_scds[,,"scd_rew_fr_sens_mu"],c(.05,.5,.95))
mean(tb_scds[,,"scd_rew_fr_sens_mu"] > 0)
mean(spef_scds[,,"scd_ma_fr_sens_mu"] > 0)
quantile(tb_scds[,,"scd_aff_fr_sens_mu"],c(.05,.5,.95))
quantile(spef_scds[,,"scd_ma_fr_sens_mu"])
quantile(spef_scds[,,"scd_resid_fr_sens_mu"])
quantile(spef_scds[,,"scd_ma_fr_sens_mu"],c(.05,.5,.95))
quantile(spef_scds[,,"scd_resid_fr_sens_mu"],c(.05,.5,.95))
mean(spef_scds[,,"scd_resid_fr_sens_mu"] > 0)
quantile(spef_scds[,,"scd_nuis_fr_sens_mu"],c(.05,.5,.95))
quantile(spef_scds[,,"scd_nuis_fr_sens_mu"],c(.025,.5,.95))
quantile(spef_scds[,,"scd_nuis_fr_sens_mu"],c(.05,.5,.95))
test <- c(1,2,3)
sd(test)
test <- c(-3,2,10,8)
sd(test)*2
sd(test*@)
sd(test*2)
sd(test*-2)
sd(test)*-2
?apply
scd_ma_fr_sens_mu <- pseudo_correct("temp_breakdown",model_out_dir,"ma_fr_sens_mu","scd_ma_fr_sens_mu")
source("~/projects/ARL_bv/code/scratch/get_breakdown_estimates.R", echo=TRUE)
scd_nuis_fr_sens_mu <- pseudo_correct("temp_breakdown",model_out_dir,"nuis_fr_sens_mu","scd_nuis_fr_sens_mu")
scd_nuis_fr_sens_mu[3,4]
is.array(scd_nuis_fr_sens_mu)
dim(scd_nuis_fr_sens_mu)
scd_nuis_fr_sens_mu[3,2]
spef_scds[3,2,"scd_nuis_fr_sens_mu"]
nuis_mu <- get_draws("temp_breakdown",model_out_dir,c("nuis_sens_fr_mu"))
nuis_mu <- get_draws("temp_breakdown",model_out_dir,c("nuis_fr_sens_mu"))
nuis_mu[3,2]
dim(nuis_mu)
nuis_mu[3,2,1]
quantile(scd_nuis_fr_sens_mu,c(.05,.5,.95))
mean(scd_nuis_fr_sens_mu < 0)
scd_ma_fr_sens_mu <- pseudo_correct("temp_breakdown",model_out_dir,"ma_fr_sens_mu","scd_ma_fr_sens_mu")
quantile(scd_ma_fr_sens_mu,c(.05,.5,.95))
mean(scd_ma_fr_sens_mu < 0)
scd_rew_fr_sens_mu <- pseudo_correct("temp_breakdown",model_out_dir,"rew_fr_sens_mu","scd_rew_fr_sens_mu")
quantile(scd_rew_fr_sens_mu,c(.05,.5,.95))
mean(scd_ma_rew_sens_mu < 0)
mean(scd_rew_sens_mu < 0)
mean(scd_rew_sens_mu < 0)
mean(scd_rew_fr_sens_mu < 0)
scd_resid_fr_sens_mu <- pseudo_correct("temp_breakdown",model_out_dir,"resid_fr_sens_mu","scd_resid_fr_sens_mu")
quantile(scd_resid_fr_sens_mu,c(.05,.5,.95))
mean(scd_resid_fr_sens_mu < 0)
mean(scd_ma_fr_sens_mu > scd_resid_fr_sens_mu)
mean(scd_ma_fr_sens_mu > scd_rew_fr_sens_mu)
mean(scd_rew_fr_sens_mu > scd_rew_fr_sens_mu)
mean(scd_rew_fr_sens_mu > scd_resid_fr_sens_mu)
sd(c(-2,2))
2.83*.08
2.83*.06
11*.05
.55*.05
.52*.05
.16*.05
.86*.05
2*.05
two_q_scds <- get_draws("two_q",model_out_dir,vars=c("scd_rew_fr_sens_mu","scd_aff_fr_sens_mu"))
quantile(two_q_scds[,,"scd_rew_fr_sens_mu"],c(.05,.5,.95))
mean(two_q_scds[,,"scd_rew_fr_sens_mu"] > 0)
quantile(two_q_scds[,,"scd_aff_fr_sens_mu"],c(.05,.5,.95))
mean(two_q_scds[,,"scd_aff_fr_sens_mu"] > 0)
mean(two_q_scds[,,"scd_rew_fr_sens_mu"] > two_q_scds[,,"scd_aff_fr_sens_mu"])
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(GGally)
library(bayesplot)
library(sigmoid)
library(abind)
source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-12_09_56_03.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-12_09_56_03.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 104 |
valrate_skipped_percent > .14 |
valence_sd < .1 |
decrate_sd < .05 |
feedrate_sd < .05)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#get mean-centered trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
combined_shrink_exdec <- fit_stan_model(stan_file = paste0(stan_model_dir_s22fu,"combined_shrink_exdec.stan"),
model_out_dir = model_out_dir,
raw_data = trials,
study = "s22fu",
skip=c("waic","check_csvs"),
n_t=104)
combined_shrink <- read_fsml("combined_shrink",model_out_dir=model_out_dir)
fsml_compare(combined_shrink, combined_shrink_exdec)
combined_shrink$loo
combined_shrink_exdec$loo
49872/24936
n_s
120*104*@
120*104*2
combined_shrink_exdec$loo <- combined_shrink_exdec$fit$loo(variables="log_lik")
fsml_compare(combined_shrink_exdec,combined_shrink)
temp_loo <- combined_shrink_exdec$loo
combined_shrink_exdec <- read_fsml("combined_shrink_exdec",model_out_dir=model_out_dir)
combined_shrink_exdec$loo <- temp_loo
saveRDS(combined_shrink_exdec,file=output_dir,"/Users/dp/projects/s22_follow_up/output/results/stan_model_fits/combined_shrink_exdec/fit_stan_model_outs.rds")
saveRDS(combined_shrink_exdec,file="/Users/dp/projects/s22_follow_up/output/results/stan_model_fits/combined_shrink_exdec/fit_stan_model_outs.rds")
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(GGally)
library(bayesplot)
library(sigmoid)
library(abind)
source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-12_09_56_03.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-12_09_56_03.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 104 |
valrate_skipped_percent > .14 |
valence_sd < .1 |
decrate_sd < .05 |
feedrate_sd < .05)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#get mean-centered trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
#Create direction vectors, where the dimensions are int he order:
#       Vb,Qcd,Qud,Vt,Qcf,rc,ru
tde <- c(-.5,.5,0,0,0,0,0)
q_ch <- c(0,1,0,0,0,0,0)
q_reg <- c(0,.5,-.5,0,0,0,0)
pwrd <- c(0,0,0,-.5,0,.5,0)
rpe <- c(0,0,0,0,-.5,.5,0)
rew <- c(0,0,0,0,0,1,0)
out_reg <- c(0,0,0,0,0,.5,-.5)
dvec_mat <- cbind(tde,q_ch,q_reg,pwrd,rpe,rew,out_reg) #turn into matrix
combined_shrink_fit <- load_cmdstan_fit(model_out_dir=model_out_dir,"combined_shrink")
cs_draws <- combined_shrink_fit$draws(c("dpiw_mu","fpiw_mu")) #get draws array
#vec_ws <- apply(cs_draws,c(1,2),vec_optim,dvec=dvec_mat) #get vector weights
#vec_ws_org <- aperm(vec_ws,c(2,3,1)) #rearrange to be in the same order that they were in the draws array
#dimnames(vec_ws_org)[[3]] <- c("tde","q_ch","q_reg","pwrd","rpe","rew","out_reg") #name meaningfully
#save(vec_ws_org,file=paste0(model_out_dir,"vec_ws_s2.RData"))
load(paste0(model_out_dir,"vec_ws_s2.RData"))
#plot normed weights
mn_data <- apply(cs_draws,c(1,2),function(x) sum(abs(x))) #get the manhattan norms for each data vector by summing the absolute values
comb_array <- abind(vec_ws_org,mn_data,along=3) #staple mn_data to the back of the third dimension of the vector weight array
vec_ws_norm <- apply(comb_array,c(1,2), get_ports) #get portions of relationship accounted for
#have to rearrange and name again
vec_ws_norm_org <- aperm(vec_ws_norm,c(2,3,1))
dimnames(vec_ws_norm_org)[[3]] <- c("tde","q_ch","q_reg","pwrd","rpe","rew","out_reg","resid") #name meaningfully
#create interval plots for manhattan norm ratios
variable_intervals_s2<- create_interval_plot(arr = vec_ws_norm_org,names = c("out_reg","pwrd","rpe","rew","q_reg","tde","q_ch"),
xmin = -.012,xmax = .48) +
theme(panel.grid.major.x = element_line(color = "#DCDCDC", size = .47),
panel.background = element_rect(fill = "white", color = NA))
save(variable_intervals_s2,file="~/Documents/active_manuscripts/s22/figures/variable_intervals_s2.RData")
#get sub-arrays of normed weights for each theory
sv_ws <- vec_ws_norm_org[,,c(2,6)]
pe_ws <- vec_ws_norm_org[,,c(1,4,5)]
reg_ws <- vec_ws_norm_org[,,c(3,7)]
#sum them to get total theory weights
sv_ports <- apply(sv_ws,c(1,2),sum)
pe_ports <- apply(pe_ws,c(1,2),sum)
reg_ports <- apply(reg_ws,c(1,2),sum)
thr_ports <- array(c(sv_ports,pe_ports,reg_ports,vec_ws_norm_org[,,8]),dim=c(1000,4,4))
dimnames(thr_ports)[[3]] <- c("sv","pe","cc","resid") #name meaningfully
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
#create interval plots for manhattan norm ratios
variable_intervals_s2<- create_interval_plot(arr = vec_ws_norm_org,names = c("out_reg","pwrd","rpe","rew","q_reg","tde","q_ch"),
xmin = -.012,xmax = .48) +
theme(panel.grid.major.x = element_line(color = "#DCDCDC", size = .47),
panel.background = element_rect(fill = "white", color = NA))
save(variable_intervals_s2,file="~/Documents/active_manuscripts/s22/figures/variable_intervals_s2.RData")
#get sub-arrays of normed weights for each theory
sv_ws <- vec_ws_norm_org[,,c(2,6)]
pe_ws <- vec_ws_norm_org[,,c(1,4,5)]
reg_ws <- vec_ws_norm_org[,,c(3,7)]
#sum them to get total theory weights
sv_ports <- apply(sv_ws,c(1,2),sum)
pe_ports <- apply(pe_ws,c(1,2),sum)
reg_ports <- apply(reg_ws,c(1,2),sum)
thr_ports <- array(c(sv_ports,pe_ports,reg_ports,vec_ws_norm_org[,,8]),dim=c(1000,4,4))
dimnames(thr_ports)[[3]] <- c("sv","pe","cc","resid") #name meaningfully
theory_intervals_s2 <- create_interval_plot(arr = thr_ports,names = c("resid","cc","pe","sv"),
xmin = -.012,xmax = .8) +
theme(panel.grid.major.x = element_line(color = "#DCDCDC", size = 1),
panel.background = element_rect(fill = "white", color = NA))
save(theory_intervals_s2,file="~/Documents/active_manuscripts/s22/figures/theory_intervals_s2.RData")
source("~/projects/spring_2022_study/code/functions/s22_utilities.R", echo=TRUE)
#create interval plots for manhattan norm ratios
variable_intervals_s2<- create_interval_plot(arr = vec_ws_norm_org,names = c("out_reg","pwrd","rpe","rew","q_reg","tde","q_ch"),
xmin = -.012,xmax = .48) +
theme(panel.grid.major.x = element_line(color = "#DCDCDC", size = .47),
panel.background = element_rect(fill = "white", color = NA))
save(variable_intervals_s2,file="~/Documents/active_manuscripts/s22/figures/variable_intervals_s2.RData")
theory_intervals_s2 <- create_interval_plot(arr = thr_ports,names = c("resid","cc","pe","sv"),
xmin = -.012,xmax = .8) +
theme(panel.grid.major.x = element_line(color = "#DCDCDC", size = 1),
panel.background = element_rect(fill = "white", color = NA))
save(theory_intervals_s2,file="~/Documents/active_manuscripts/s22/figures/theory_intervals_s2.RData")
